= Awkward Array Specification (1.0-pre1)
:Author: Jim Pivarski
:Email: pivarski@princeton.edu
:Date: 1.0 expected early 2019
:Revision: 1.0-pre1
:toc:

== Introduction

Array programming is a general programming paradigm, similar to functional programming or object-oriented programming in its scope. Pioneered by APL in 1962, this paradigm has appeared primarily in interactive data processing languages aimed at data analysts and statisticians: S (1976), MATLAB (1984), S-PLUS (1988), R (1993), and Numpy (2005). Numpy, unlike its predecessors, is not a language in itself, but a foundational library for science and statistics in Python.

Array programming is mostly used to solve problems with regular, rectangular grids. It is possible to represent and operate on more complex data structures, but it is awkward to do so in current frameworks. Fortunately, this awkwardness may be hidden in a suite of higher-level array classes that present modest extensions of the array programming paradigm to the user.

https://github.com/scikit-hep/awkward-array[awkward-array] (https://pypi.org/project/awkward[awkward] on PyPI) is an implementation of complex data structures and operations in Python, depending only on https://pandas.pydata.org[Numpy]. Drop-in replacements optimized with compiled code or leveraging GPUs are foreseen, though they would present the same user interface as the Numpy-only implementation. Extensions for using awkward-array as https://pandas.pydata.org[Pandas] columns, in https://pandas.pydata.org[Numba]-compiled functions, and in distributed calculations with https://pandas.pydata.org[Dask] are also foreseen. These arrays can already be used to view https://arrow.apache.org[Arrow] data and can be persisted and reconstituted in any data format supporting Numpy arrays, such as HDF5, or named binary blobs, such as ZIP or key-value stores.

As an array programming environment for general data structures, awkward-array represents arbitrary data in a https://en.wikipedia.org/wiki/Column-oriented_DBMS[columnar] form (compatible with and a generalization of Arrow). Most operations are vectorized or vectorizable because they are applied to flat, homogeneous arrays in memory masquerading as the nested and variable-length data structures that are presented to the user. This allows for memory and computational efficiency that are hard to match with implementations on traditional "`row-wise`" data, as well as automatic porting to pure vector coprocessors, such as GPUs. The key is a random access, composable representation of https://en.wikipedia.org/wiki/Jagged_array[jagged arrays] in terms of unstructured Numpy arrays.

=== This specification

Despite awkward-array's focus on Python and Numpy, the data model it represents is language-agnostic. This document describes awkward-array as a protocol for generalizing array programming to complex structures in any environment. It is a normative document in the sense that it describes what awkward-array in Python _should_ do; discrepancies between this document and the Python implementation would usually be decided in favor of the document (though the document itself may have "`bugs`" to be fixed in a later version). It is also normative in the sense that other implementations, in C++ or MATLAB for instance, that claim to "`adhere to the awkward-array specification`" _should_ also behave as described here.

The goal of this document is to describe an array programming interface that extends a basic array programming interface. The extended interface is called "`awkward-array`" and the basic interface is a well-known starting point, such as Numpy. For simplicity, we will use Python syntax and Numpy function names, but a library in a different language or based on a different array library may still adhere to the awkward-array specification by providing a translation of these idioms.

It is not a goal of this document to explain how the awkward-array features are implemented. Drop-in replacements for the Numpy-only awkward-array library and libraries in other environments are free to implement the specification differently. They will thus have different performance characteristics. This specification cannot provide any performance hints.

Documentation is not an explicit goal of this specification, though users may read it to learn how to use any compliant implementation. Unlike documentation, however, this document describes what an awkward-array library should do, not necessarily what it does. Users are encouraged to file https://github.com/scikit-hep/awkward-array/issues[issues here] if a discrepancy is found in the Numpy-only implementation.

The major and minor version numbers of this specification, `xx.yy`, correspond to the major and minor version numbers of the Numpy-only implementation: `xx.yy` in `xx.yy.zz`. The revision number, `zz`, increases as the implementation strives toward compliance with the specification. This particular version of the specification is a pre-release; compliance is only required for released specifications.

A library may implement more features than those described in this specification without affecting its compliance. If it implements fewer classes or fewer methods, it can only be said to be "`partially compliant,`" and would have to enumerate the missing classes or methods.

=== Basic array protocol

Necessary features of the underlying array library are described in this section for two reasons: to establish a syntax used in the rest of this document and as a basis for translating idioms of non-Numpy libraries into the language of this document. For instance, another language may use a function to extract slices of an array, rather than Python's `array[start:stop:step]` syntax. If so, the awkward-array idiom in that language would use the same function name and arguments, rather than the Python ones.

The underlying array library must have the following features or some translation thereof.

It must be possible to represent ordered sequences of primitive values, known as *arrays*. An array is homogeneous: all values in an array have the same *dtype*, or primitive data type. Primitive types include integers, floating point numbers, and boolean (true/false) values. An awkward-array library inherits the primitives of the underlying library -- if a base array library doesn't support complex numbers (for instance), then neither does its awkward-array extension. Arrays need not be fixed-size, contiguous in memory, with only fixed-bytesize primitives, but these are the simplest cases.

It must be possible to construct _N_-dimensional arrays for any positive integer _N_. We will refer to an array's size in all dimensions as its *shape*, a tuple of positive integers whose product is the total number of elements in the array. The *length* of an array is the array's size in its first dimension.

t must be possible to *extract* an array element by integer index or a tuple of _N_ integer indexes for an _N_-dimensional array. In this document, we will use 0-indexing: `0` extracts the first element, `1` extracts the second, etc. If an index is greater than or equal to _N_, it is out of bounds. An array library with 1-indexing (`1` extracts the first element) would correspondingly have 1-indexing in its awkward-array extensions. We will use a number between square brackets after the array, as in `myarray[5]`, or a comma-separated tuple like `myarray[3, 1, 4]`, to represent extraction.

The array library may provide a mechanism for counting from the end of an array dimension. In Python, `-1` refers to the last element, `-2` to the second-to-last element, etc. We will use that convention. Given a negative index `i` and a dimension size `d`, the standard index is `i + d`. If the standard index is still negative, the index is out of bounds.

It must be possible to *slice* an array dimension to get a subsequence of that array along any dimension. A slice is defined by a *start* index (lower bound element number), a *stop* index (upper bound element number), and an optional *step* (stride length, for skipping a regular number of input elements between each returned element). In this document, we will use inclusive start values (the lower bound is included in the resulting subsequence) and exclusive stop values (the upper bound is not included). A step of `1` is equivalent to no step, and the step must not be `0`, though negative values may be allowed (to reverse order). If either start or stop is not provided, they may be assumed to be `0` and the size of the dimension (respectively) if step is positive, or one less than the size of the dimension and one less than `0` (respectively) if step is negative. If the difference between step and start is not an integer multiple of step, we take that the subsequence to be truncated at the last element before stop. If either start or step are beyond the bounds of the array, we take them to be truncated to the nearest legal values, which may result in an empty subsequence, but not an error. If negative indexes are allowed for element extraction, they may be allowed for slicing as well. The Python syntax for this operation is `myarray[start:stop:step]` (in which any `start`, `stop`, or `step` may be missing or `None`, and the second colon may be omitted if there is no `step`). We will use this syntax in this document.

It must be possible to *mask* elements in an array dimension by a 1-dimensional boolean array of the same size as that array dimension. The result of such an operation is a sequence in the same order containing only the elements for which the matching boolean value is true. The Numpy syntax for this operation is to put the boolean `mymask` array in square brackets after the array: `myarray[mymask]`, but it may be a named function call.

It must be possible to *gather* elements in an array dimension by a 1-dimensional integer array, using the integer array as extraction indexes. The result of such an operation, denoted `myarray[myindexes]`, is a sequence with the same length and order as the indexing array `myindexes`, containing elements from `myarray`. The same rules apply to the elements of the indexing array as for single-element extraction. (In Numpy, this is sometimes called "`fancy indexing,`" though sometimes that term encompasses masking as well, so we will use "`gather`" in this document, as this is what the operation is called in SIMD programming.) As with masking, this may be a named function call.

It must either be possible to apply selections to multiple dimensions in a single call or to apply a selection to a specified dimension, not necessarily the first. For instance, we could extract from the first dimension, slice the second, mask the third, and gather the fourth in Numpy by separating requests with commas: `myarray[5, start:stop:step, mymask, myindexes]`. Selecting in multiple dimensions would allow selection in a specified dimension by passing all-inclusive slices to all dimensions before the dimension of interest: `myarray[:, :, :, selection]`. Selecting a specified dimension would allow selecting multiple dimensions by composition, so either is sufficient.

It must be possible to map arithmetic operations across all elements of one or more arrays. Any *kernel* function of _n_ primitive type arguments returning a primitive type result can be applied to _n_ equal-shape arrays and return a single new array of results with the same shape. The kernel function must be pure (no side effects), and many would be expressible as special syntax, such as `+` for addition, `-` for subtraction, etc. In Numpy, these are called "`universal functions`" or "`ufuncs,`" but this is such a specific protocol that we use a more general word, *mapped kernels*.

If any arguments in a mapped kernel have a scalar primitive type, rather than an array, they should be replaced by a constant array of the correct shape before mapping the kernel. If an argument has the correct dimensionality but some of its dimensions have size `1` where the other arguments have a size greater than `1`, this dimension should be similarly expanded to a constant before mapping. These expansions do not need to be literal -- the result is calculated _as though_ the scalar or singleton dimension were a constant array. This conceptual expansion is known as *broadcasting* in Numpy and in this document.

It must be possible to reduce an array by a binary arithmetic operation along a given dimension. The array is reduced in dimension by one; 1-dimensional arrays are reduced to primitive scalars. Empty dimensions or arrays may be reduced to the operation's identity if the operation has an identity -- it must return an error otherwise. The identity for addition is `0`, multiplication is `1`, and we may take the identity for minimization and maximization to be the largest and smallest values available in the primitive data type, respectively. For instance, the minimum of an empty array of floating point numbers may be taken to be infinity.

Any array library supporting these basic features may be extended as specified in this document.

== Features provided by an awkward-array library

An awkward-array library provides the above features in the following new contexts.

   * *Jaggedness:* multidimensional arrays with a non-constant shape. A jagged array is an array of arbitrary-length lists.
   * *Product types:* extend a primitive type system with record structures -- objects with named, typed fields.
   * *Sum types:* extend a primitive type system with tagged unions -- values that may have one of a set of enumerated types. This permits arrays to be heterogeneous in a controlled way.
   * *Option types:* extend a primitive type system with a nullable type -- values that may be "`missing.`"
   * *Cross-references and cyclic references:* extend a primitive type system with values that may be references to another array, including a parent of the array in which they reside. This adds "`pointers`" to the type system in a controlled way: references must point to elements of a specified array.
   * *Opaque object types:* allow array elements to virtually contain instances of any type expressible in a programming language, provided that it can be constructed strictly from elements of the array.
   * *Object methods:* adds user-defined methods to arrays, usually to emulate object methods as mapped kernels.
   * *Indirection:* allows arrays to be defined as a cherry-picked subset of other arrays.
   * *Non-contiguousness:* allows arrays to be non-contiguous in memory by mapping indexes. This virtually concatenates data from separate chunks into a single logical array without copying.
   * *Laziness:* allows arrays to be loaded or generated on demand, allowing arrays that have not yet been *materialized* to be treated on the same footing with arrays that have.

Jaggedness, product types, sum types, option types, and references extend the expressivity of basic arrays to a complete, hierarchical data model. General data containers like https://developers.google.com/protocol-buffers[Protocol buffers], https://thrift.apache.org[Thrift], https://avro.apache.org[Avro], and https://parquet.apache.org[Parquet] present this data model, with the exception of references.

Object types and methods generalize it further, allowing any type permitted by a programming language such as Python, with a loss of cross-language compatibility.

Indirection, non-contiguousness, and laziness do not affect data type: they are *purely low-level* features.

Taken together, these features promote array programming to a wider set of applications.

=== High-level types

To describe how awkward-array extends basic array types, we start by defining a notation that encompasses both. Basic arrays can be fully described by their dtype and shape. These parameters are not sufficient for awkward-array.

==== Basic arrays

Any array, including those in awkward-array, can be thought of as a function that maps extraction indexes to values. The functional type of a basic, 1-dimensional array with value type `T` and length `n` could be written as

[source]
----
[0, n) -> T
----

That is, the array is a function that takes an integer greater than or equal to `0` and less than `n` as its only argument, and returns a value of type `T`. The possible value types are the primitive types of the basic array library. Knowing the array's type signature as an extraction function is enough to deduce its behavior in slicing, masking, and gathering.

A 2-dimensional array with shape `(n, m)` is a function that returns a function.

[source]
----
[0, n) -> [0, m) -> T
----

That is, if we pass an integer `[0, n)` to the 2-dimensional array, we get a 1-dimensional array; if we pass an integer `[0, m)` to that 1-dimensional array, we get a primitive value of type `T`. This https://en.wikipedia.org/wiki/Currying[currying] can be applied indefinitely to describe arrays of any dimensionality. The shape in a tuple syntax like Numpy's is more concise, but we will need the longer form.

==== Jagged arrays

https://en.wikipedia.org/wiki/Jagged_array[Jagged arrays] are like multidimensional arrays in the number of integer arguments that must be passed before obtaining a scalar primitive type, but not all of the arguments have precise domains. A simple jagged array of length `n`, only one level of jaggedness, and primitive type `T` would be expressed as

[source]
----
[0, n) -> [0, inf) -> T
----

because the second argument may be any non-negative integer. Unlike a basic array, some values for this second parameter, allowed by the above expression, would be rejected in practice. For example, the array

[source, python]
----
[[1, 2, 3], [], [4, 5]]
----

would accept only `[0, 3)` as a second argument if the first argument is `0`, would accept nothing (empty domain) if the first argument is `1`, and would accept only `[0, 2)` if the first argument is `2`. We have a choice between expressing the type signature fully, such that any arguments satisfying that signature would never fail to return a primitive value, and underexpressing it with `[0, inf)`, which has the advantage that the length of the type signature does not scale with the length of the array itself. Brevity is more useful for our purposes.

In this document, we refer to a full listing of the sizes of subarrays as a jagged array's *jagged structure*. Some operations on two or more jagged arrays can only be performed if they have the same jagged structure.

Continuing this line of reasoning, a doubly jagged array, such as

[source, python]
----
[[[1, 2, 3], []], [[4, 5]], []]
----

would have type

[source]
----
[0, n) -> [0, inf) -> [0, inf) -> T
----

==== Product types

https://en.wikipedia.org/wiki/Product_type[Product types] are variously known as "`records,`" "`structs,`" "`compounds,`" "`classes,`" etc. They are values that contain a fixed set of named, typed attributes. They are "`products`" in the sense of Cartesian products: the set of records containing a floating point `x` and an integer `i` is the Cartesian product of the set of floating point values and the set of integer values.

To extract an attribute from a record, we give the record the attribute's name. In a dynamically typed language, this amounts to passing a string argument; in a statically typed language, this string is usually a parsed, checked, compile-time literal. In either case, we can express it as an extraction function like

[source]
----
'x' -> float64
'i' -> int64
----

The names are enumerated because there is a fixed set of choices, and each choice returns a potentially different type. An array of length `n` containing these records is

[source]
----
[0, n) -> 'x' -> float64
          'i' -> int64
----

In general, the form is a sequence of name, type specification pairs called *fields* that can be embedded in a type specification. Product types with the same set of fields, in any order, are equivalent, though an awkward-array library should maintain the user-specified order for readability.

Jagged arrays, basic arrays, and record structure may be freely intermixed. An awkward-array type with these elements is, in general, a tree:

[source]
----
[0, n) -> [0, inf) -> 'one'   -> bool
                      'two'   -> [0, inf) -> int64
                      'three' -> 'x' -> [0, inf) -> float64
                                 'y' -> complex128
----

Extraction indexes (integers) and field names (strings) can be commuted (swapped in order). Extraction indexes do not commute with other extraction indexes, as this would violate dimension order, and field names do not commute with other field names, as this would violate records of different nesting depths, but extraction indexes commute with field names. Reversing an integer index and a string name amounts to selecting column before row or row before column in a table.

Ignoring this distinction hides the distinction between https://en.wikipedia.org/wiki/AOS_and_SOA[an array of structs and a struct of arrays], so that array manipulation code does not depend on this difference (just as Numpy hides C vs. Fortran order as an internal array flag). For instance,

[source]
----
[0, n) -> 'x' -> [0, m) -> T1
          'y' -> [0, m) -> T2
----

is equivalent to

[source]
----
[0, n) -> [0, m) -> 'x' -> T1
                    'y' -> T2
----

because all fields in the record have the same array dimension `m`, this array dimension can be commuted toward the root. The second form is considered canonical: extraction indexes should be commuted toward the root to reduce redundancy.

The same commutation is possible for jagged dimensions (perhaps surprisingly). A jagged array of records is equivalent to a record of jagged arrays, all with the same jagged structure. If we had a detailed type schema that encoded this jagged structure, rather than hiding it under the symbol `[0, inf)`, we could perform the same commutation on jagged arrays as on regular arrays. However, as a limitation of this notation,

[source]
----
[0, n) -> 'x' -> [0, inf) -> T1
          'y' -> [0, inf) -> T2
----

can't be commuted to

[source]
----
[0, n) -> [0, inf) -> 'x' -> T1
                      'y' -> T2
----

because we do not know if fields `x` and `y` have the same jagged structure. (A record with a single field can be commuted.)

==== Sum types

https://en.wikipedia.org/wiki/Tagged_union[Sum types] are known as "`tagged unions`" in programming languages that support them. They are values that may be any one of an enumerated set of types. They are "`sums`" in the sense that they are dual to product types: if a record type with two fields of types _T~1~_ and _T~2~_ is denoted _T~1~ * T~2~_, a union type that can be  _T~1~_ or _T~2~_ is _T~1~ + T~2~_, obeying a distributive law. Unions are useful for building heterogeneous arrays in a controlled way. Class inheritance in object-oriented programming is a limited case of sum typing.

We delimit the enumerated types in a sum type with a vertical bar. Consider, for instance, a value that may be a floating point number or a jagged list of booleans.

[source]
----
float64          |
[0, inf) -> bool
----

These may be embedded in any type specification.

[source]
----
[0, n) -> (float64          |
           [0, inf) -> bool )
----

Parentheses are required because the fields of a product type (denoted by adjacency) have higher operator precedence than the enumerations of a sum type. For instance,

[source]
----
[0, n) -> ('x' -> float64
           'y' -> float64
           'z' -> float64   |
           [0, inf) -> bool )
----

for unions of _x, y, z_ records with jagged arrays of booleans, and

[source]
----
[0, n) -> ('x' -> float64
           'y' -> float64
           'z' -> float64 |
           'x' -> int64
           'y' -> int64   )
----

for unions of _x, y, z_ floating point records with _x, y_ integer records.

Sum types with the same set of enumerated types, in any order, are equivalent, though an awkward-array library should maintain the user-specified order for readability and an unambiguous type resolution order. (A value may be a member of more than one of the enumerated types.)

Sum types may be nested, though they are equivalent to their flattened form. For instance,

[source]
----
[0, n) -> (bool          |
           int64         |
           (float64    |
            complex128 ) )
----

is equivalent to

[source]
----
[0, n) -> (bool       |
           int64      |
           float64    |
           complex128 )
----

==== Option types

An important special case of sum types is to describe missing data with a `null`, `None`, `na`, or `NaN` token. This could be expressed as a union of the non-missing data type with a https://en.wikipedia.org/wiki/Unit_type[unit type] for `None`, but building these constructions manually (as in https://avro.apache.org[Avro]) becomes unwieldy when most data can be missing (is "`nullable`") and it forces us to consider an array that can only be filled with `None` as a legitimate array type. Instead, we introduce another element: an option type.

Option types have one parameter, the non-missing type `T`, and indicate that values may be missing. When extracting data from such an array, the values might have type `T` or might be `None` (in Python). We denote this with a question mark and parentheses; for example,

[source]
----
[0, n) -> ?(float64)
----

or

[source]
----
[0, n) -> [0, inf) -> ?([0, 3) -> int64)
----

or

[source]
----
[0, n) -> ?('x' -> float64
            'y' -> float64)
----

Option types may be nested, though they are equivalent to their flattened form. For instance,

[source]
----
[0, n) -> ?(?(float64))
----

is equivalent to

[source]
----
[0, n) -> ?(float64)
----

Note that Numpy has a `numpy.ma.MaskedArray` type, but awkward-array has its own `awkward.MaskedArray`. The awkward-array masked type can contain non-basic arrays (jagged arrays, tables, etc.) and uses `None` to represent missing values, rather than `numpy.ma.masked`, an object with surprising properties.

==== Cross-references and cyclic references

As described above, an awkward-array type can be a tree of primitive types, basic arrays, jagged arrays, product types, sum types, and option types. An arbitrary tree of types is powerful (see https://developers.google.com/protocol-buffers[Protocol buffers], https://thrift.apache.org[Thrift], https://avro.apache.org[Avro], and https://parquet.apache.org[Parquet]), but a given type tree sets an upper limit on the depth of values that are members of that type. There would be, for instance, no type specification for JSON, or even the subset of JSON corresponding to "`lists that contain numbers or other lists.`"

This constraint can be lifted by allowing the type specification to contain references to other parts of itself. We represent these references by assigning a subexpression with `:=` and then referring to that subexpression by name, rather than rewriting the subexpression. If the reference is not contained within the subexpression it references, it is a *cross-reference* and this notation reduces verbosity.

In the following example of a cross-reference, a dataset contains _x, y, z_ data points and moving windows representing contiguous ranges of these data points. The window has access to data beyond its own array element, but it does not have access to anything beyond the `data` field.

[source]
----
[0, n) -> 'data'   -> T0 := 'x' -> float64
                            'y' -> float64
                            'z' -> float64
          'window' -> [0, inf) -> T0
----

If the reference is contained within the subexpression it references, it is a *cyclic reference* and the assignment notation avoids infinite recursion.

For example, consider lists that contain numbers or other lists, such as the value below.

[source, python]
----
[[1.1, [2.2, [3.3, 4.4, []]]]]
----

Lists with this depth and no greater could be expressed as belonging to a sum type of jagged arrays nested four levels deep. Lists like the above at any depth can be expressed as belonging to

[source]
----
[0, n) -> T0 := (float64        |
                 [0, inf) -> T0 )
----

The subexpression `T0` represents floating point numbers or jagged arrays of `T0`. Trees of any depth belong to this type, as do cyclic graphs. With these elements, we can represent a wide variety of data structures, as general as most programming languages.

==== Opaque object types

Data constructed from primitives, basic arrays, jagged arrays, product types, sum types, option types, cross-references, and cyclic references are called *pure constructions*. They are entirely expressible in terms of basic arrays, which are themselves portable across environments. However, if a programming task requires special types, such as instances with particular methods or inheritance from a third-party interface, then pure constructions would have to be wrapped.

Wrapped data are represented in the type system as *opaque types*, types outside of awkward-array's system. For instance, we may emulate an array of opaque objects by constructing these objects from an awkward-array upon extraction. This opaque constructor, which may be a helper function rather than a class's built-in constructor, is included in the type specification to represent such a case.

For example, an array of Python strings would be

[source]
----
[0, n) -> <class 'str'>
----

with a jagged array of character primitives hidden behind the string constructor.

Opaque objects cannot be shared across platforms the way that pure constructions can. Gaining flexibility in one way diminishes it in another.

==== Type representation

In awkward-array, the above types are represented by the following classes in `awkward.type`:

   * `Type` is an abstract base class for type objects. Types may be `Types`, Numpy dtypes, or Python callables.
   * `ArrayType(n, m, ..., to)` constructs a linear sequence like `[0, n) -> [0, m) -> ... -> to`. At least two arguments are required, and all arguments but the last must be positive integers or infinity (which is floating point) or a string, to make a single-field table. The last argument must be a basic array dtype (for a primitive type) or a Python callable (for an opaque type). `ArrayType` objects are recursively linked lists: each instance has two members, `takes` and `to`, where `takes` is a single number and `to` is the rest of the sequence.
   * `TableType(**fields)` constructs a product type from a mapping of field names to field types. The preferred way to construct a `TableType` is through the `&` operator, which glues single-field tables into a multi-field table. The `TableType` has get-item and set-item methods for manipulation as a Python dict.
   * `UnionType(*possibilities)` constructs a sum type from a sequence of types. The preferred way to construct a `UnionType` is through the `|` operator. The `UnionType` has get-item and set-item methods, as well as `append`, for manipulation as a list.
   * `OptionType(type)` constructs an option type from a type parameter. It has a `type` attribute.
   * There are no special classes for cross-references and cyclic references. Build an internally referenced type object to represent an internally referenced type. All `Type` methods except for those that attempt to yield equivalent Numpy types (`dtype` and `shape`) should be recursion-safe.

This module has two functions:

   * `fromarray(array)` returns the type specification of any array, whether an awkward-array or a basic (Numpy) array.
   * `fromnumpy(shape, dtype, masked=False)` returns the type specification of a basic (Numpy) array directly from shape, dtype, and masked parameters.

== General properties of all array classes

Array classes are defined in the `awkward.array` submodule but are all accessible directly from the top-level `awkward` module. They all have the following properties.

   * They have primary constructors that define the array in terms of the most general components; for example, `starts`, `stops`, and `content` for `JaggedArray` and `tags`, `offsets`, and `contents` for `UnionArray`.
   * They have class-method constructors with more convenient constructors, such as `JaggedArray.fromoffsets(offsets, content)` and `UnionArray.fromtags(tags, contents)`.
   * Primary constructor arguments are read-write properties of the array object.
   * *Single-property validity* tests, which verify conditions that are a function of only one property, are performed in the constructor and upon assignment. Errors raise exceptions.
   * *Whole-array validity* tests, which verify conditions that are relationships among properties in an array, are performed just before array evaluation. Errors raise exceptions.
   * All arrays have get-item methods that perform extraction, slicing, masking, and gathering. If the array contains a product type, a string selects a column and a sequence of strings selects multiple columns.
   * String indexes commute with extraction/slicing/masking/gathering, but they can't be used in the same set of square brackets, the way extraction/slicing/masking/gathering can.
   * All arrays have a set-item method to add columns to a `Table` (product type), but _only_ for this purpose. Elements of an awkward-array cannot be changed in place without digging down to the basic array (and that can have hard-to-predict consequences).
   * All arrays have a length (for `len`) and Pythonic iteration (for `for` loops).
   * String representations (`str` and `repr` in Python) show logical content in square brackets without commas (spaces only), limited to 6 elements at each level of depth (filling in missing with three dots: `...`). In Python, the `repr` representation includes the top-most class name but `str` does not. String representations trigger whole-array validity tests.
   * The `type` read-only property returns a representation of the array type.
   * The `dtype` and `shape` read-only properties attempt to express the array as a basic (Numpy) array, which can involve information loss.
   * The `columns` read-only property returns a list of field names for the shallowest `Table` within the array that are valid Python identifiers. The `allcolumns` read-only property is not restricted to valid Python identifiers.
   * The `tolist()` method returns a Pythonic representation of the data (also valid JSON, if all floating point values are finite). Nested arrays become nested Python lists and `Table.Rows` become dicts of name, field value pairs.
   * The `valid()` method tests whole-array validity without raising an exception.

The `awkward.array.base.AwkwardArray` abstract base class has switches to control global behavior. They may be set at any level: on the base class to affect all awkward-array types, all instances, or on a concrete class for all instances of that class, or on a single instance. In languages other than Python, an alternative mechanism may be substituted.

   * `allow_tonumpy` _default:_ `True`, if `False`, any operation that would convert an awkward-array type into a basic (Numpy) array instead raises a `RuntimeError`.
   * `allow_iter` _default:_ `True`, if `False`, any attempt to iterate over an awkward-array in Python (except via `str` or `repr`) would raise a `RuntimeError`.
   * `check_prop_valid` _default:_ `True`, if `False`, skip single-property validity checks.
   * `check_valid` _default:_ `True`, if `False`, skip whole-array validity checks.

The default primitive types for various roles are given below.

|===
| Awkward type | Numpy dtype | Purpose

| `DEFAULTTYPE` | `float64` | default array content
| `CHARTYPE` | `uint8` | array content for byte-granularity arrays
| `INDEXTYPE` | `int64` | default type for indexes (signed so that subtraction does not change type)
| `TAGTYPE` | `uint8` | default type for tagged union tags
| `MASKTYPE` | `bool_` | type for byte masks
| `BITMASKTYPE` | `uint8` | type for bit masks
| `BOOLTYPE` | `bool_` | type for boolean data
|===

== Jaggedness

https://en.wikipedia.org/wiki/Jagged_array[Jagged arrays] have a logical structure that is independent of how they are represented in memory, but since awkward-array defines this structure in terms of a basic array library (Numpy), the structure we choose is a visible part of the awkward-array specification. This introduction presents many ways to represent jagged arrays, their advantages and disadvantages, before specifying the `JaggedArray` class itself. The `JaggedArray` class uses the most general representation internally with conversions to and from the other forms.

One natural way to represent a jagged array is to introduce markers in the serialized content where each variable-length nested list begins or ends, or to insert nested list sizes before each nested list (as in the https://avro.apache.org[Avro] protocol) to avoid having to distinguish content values from markers. However, this "`row-wise`" representation interrupts vectorized processing of the content. Another natural way is to create an array of pointers to nested lists, like Numpy's object array, but this is even worse because it additionally increases memory latency.

Columnar representations keep the contents of the nested lists in a single, contiguous array (a "`column`"). The https://root.cern[ROOT] file format was possibly the first columnar representation of jagged arrays (1995), though the intention was for efficient packing and compression on disk, rather than processing in memory. However, the columnar arrays of a ROOT file may be transplanted into memory for efficient computation as well. The https://parquet.apache.org[Parquet] file format is another, though it modifies ("`https://github.com/julienledem/redelm/wiki/The-striping-and-assembly-algorithms-from-the-Dremel-paper[shreds]`") the data in a way that is hard to use without restructuring it. The https://arrow.apache.org[Arrow] in-memory format uses one of the methods described below.

The simplest way to represent a jagged array with columnar arrays is to store flattened *content* in one array and *counts* of the number of elements in each interior list in another array. The starting and stopping index of one element -- an interior list -- can unambiguously be determined by summing counts up to the element of interest. This operation is _O(N)_ in array length _N_, unfortunately. It is, however, *composable*, in that nested lists of nested lists (and so on) can be constructed by setting one jagged array as the content of another. For example, to represent the following nested structure:

[source, python]
----
[[], [[1.1, 2.2, 3.3], [], [4.4, 5.5]], [[6.6, 7.7], [8.8]]]
----

we note that the first level of depth contains lists of length `0`, length `3`, and length `2`. Inside that (and ignoring boundaries of the first level of depth), the second level of depth contains lists of length `3`, `0`, `2`, `2`, and `1`. Inside that, the content consists of floating point numbers. (The type for this doubly jagged array is `[0, inf) -> [0, inf) -> float64`.) It can be represented by three arrays:

   * outer counts: `0, 3, 2`
   * inner counts: `3, 0, 2, 2, 1`
   * inner content: `1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8`

The inner jagged array instance has inner counts and inner content as its counts and content, and the outer jagged array instance has outer counts as its counts and the inner jagged array as its content. Recursively, we can construct jaggedness of any depth from this one primitive.

To address the random access problem, we can consider replacing counts with its integral, *offsets*. An offsets array is a cumulative sum of counts, which avoids the need to recompute the sum for each lookup. Given a counts array, we compute the offsets by allocating an array one larger than counts, filling its first element with `0`, and filling each subsequent element `i` with `offsets[i] = offsets[i - 1] + counts[i - 1]`. Similarly, counts is the derivative of offsets, and can be derived with a vectorized `counts = offsets[1:] - offsets[:-1]`. (There is a https://en.wikipedia.org/wiki/Prefix_sum#Algorithm_1:_Shorter_span,_more_parallel[vectorized algorithm] for computing the cumulative sum as well.) The nested list at index `i` is `content[offsets[i]:offsets[i + 1]]`. The Arrow in-memory format uses offset arrays to define arbitrary length lists.

Like jagged arrays defined by counts, jagged arrays defined by offsets are composable, but unlike counts, any element may be accessed in _O(1)_ time. There are only a few situations in which counts may be preferable:

   * counts are non-negative small integers, which can be packed more efficiently with https://en.wikipedia.org/wiki/Variable-length_quantity[variable width encoding] and lightweight compression (both of which destroy _O(1)_ lookup time anyway);
   * counts are position-independent, allowing a large dataset to be processed without knowing its position in the sequence. This is particularly useful for _generating_ large sequences when the total size of each parallel chunk is not known until it is complete.

One shortcoming that counts and offsets share is that they can only describe dense content. The data for list `i + 1` must appear directly after the data for list `i`. If we wish to view the jagged array with any interior elements removed, we would have to make a new copy of the content with those lists removed, which could trigger a deep recursive copy. It would be more efficient to allow the content to contain unreachable elements, so that these selections can be zero-copy views.

A jagged array based on counts can have unreachable elements: any content at indexes greater than or equal to `sum(counts)` are effectively not in the jagged array. A jagged array based on offsets can have uncreachable elements at indexes less than `offsets[0]` and greater than or equal to `offsets[-1]`, assuming that we allow `offsets[0]` to be greater than `0`. To allow interior elements to be unreachable, we can generalize offsets into two arrays, *starts* and *stops*. These two arrays (nominally) have the same shape as each other and define the shape of the jagged array. The nested list at index `i` is `content[starts[i]:stops[i]]`. Given an offsets array, we can compute starts and stops by `starts = offsets[:-1]` and `stops = offsets[1:]`.

A jagged array defined by starts and stops can skip any interior content, can repeat elements, can list elements in any order, and can even make nested lists partially overlap. Skipping elements is useful for masking, repeating elements is useful for gathering, and reordering elements is useful for optimizing data to minimize disk page-reads. (No use for partial overlaps is currently known.) A potential cost of separate starts and stops is that it can double memory use and time spent in validation tests. However, if the starts and stops happen to be dense and in order, they can be views of a single offsets array and if this case is detected, simplified calculations may be performed.

The starts/stops scheme is a very general way to describe a jagged array from the outside-in, for efficient extraction, slicing, masking, and gathering. It is a tree structure with pointers (indexes) from the root toward the leaves. For reduction operations, however, we need pointers from the leaves toward the root: an array with (nominally) the same length as the content, indicating where each nested list begins and ends. (This is similar to normal forms in database management, and the scheme used by https://parquet.apache.org[Parquet], though the latter is transformed and highly bit-packed.)

The simplest inside-out scheme is associate an integer with each content element, and distinct values of these integers indicate different nested lists. (This is closest to database normal form: aggregation over nested lists could then be performed by an SQL group-by.) For efficient access, especially if the jagged array is distributed and acted upon in parallel, we can stipulate that identical values are contiguous, since content belonging to the same nested list must be contiguous in the starts/stops scheme. Such an array is called a *uniques* array. It underrepresents a jagged array in two ways:

   * it doesn't specify an ordering of elements (though we can assume the content is in increasing order), and
   * it can't express any empty lists (though we can assume that there are none).

Because of this underrepresentation, a uniques array can be used to generate a jagged array but can't be used to represent one that is already defined by starts and stops. We can modify the definition of uniques to more fully specify a jagged array by requiring the unique values associated with every nested list to be the index of the corresponding starts element. This specialized uniques array is called *parents*.

For example, with a jagged array logically defined as

[source, python]
----
[[], [1.1, 2.2, 3.3], [], [4.4, 5.5], [6.6, 7.7], [8.8], []]
----

the starts, stops, and content are

   * starts: `0, 0, 3, 3, 5, 7, 8`
   * stops: `0, 3, 3, 5, 7, 8, 8`
   * content: `1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7, 8.8`

and the parents array is

   * parents: `1, 1, 1, 3, 3, 4, 4, 5`

The first three elements of parents (`1, 1, 1`) associate the first three contents (`1.1, 2.2, 3.3`) with element `1` of starts and stops. The next two elements of parents (`3, 3`) associate the next two contents (`4.4, 5.5`) with element `3` of starts and stops. The fact that parents lacks `0` and `2` indicate that these are empty lists. Only empty lists after all content are unrepresented unless the total array length is also given. Out of order elements can easily be expressed because parents does not need to be an increasing array. Unreachable elements can also be expressed by setting their values to a negative value. However, repeated elements cannot be expressed, so a parents array cannot represent the result of a gather operation. Likewise, partial overlaps cannot be expressed.

Given a starts array and its corresponding parents, the following invariant holds for all `0 <= i < len(starts)`:

[source, python]
----
parents[starts[i]] == i
----

and the following holds for all `0 <= j < len(content)` that are at the beginning of a nested list:

[source, python]
----
starts[parents[j]] == j
----

Although parents is a highly expressive inside-out representation, another that is sometimes useful, called *index*, consists of integers that are zero at the start of each nested list and increase by one for each content element. For instance, the above example has the following index:

   * index: `0, 1, 2, 0, 1, 0, 1, 0`

These values are local indexes for elements within the nested lists. For all `0 <= j < len(content)`, the following invariant holds:

[source, python]
----
starts[parents[j]] + index[j] == j
----

It is also useful to wrap the index array as a jagged array with the same jagged structure as the original jagged array, because then it can be used in gather operations.

All of the above discussion has focused on jagged arrays and nested jagged arrays without any *regular* array dimensions -- that is, without dimensions whose sizes are known to be constant. Jagged arrays are more general, so a regular array may be emulated by a jagged array with constant counts, but this clearly less efficient than storing the regular dimension sizes only once. Regular dimensions that appear after (or "`inside`") a jagged dimension can be represented by simply including a multidimensional array as content in a jagged array. That is, to get an array of type

[source]
----
[0, inf) -> [0, m) -> T
----

construct a jagged array whose content is an array of type `[0, m) -> T`. Regular dimensions that appear before (or "`outside`") a jagged dimension are harder: the starts and stops of the jagged array must both have the shape of these regular dimensions. That is, to get an array of type

[source]
----
[0, n) -> [0, inf) -> T
----

the starts and stops must be arrays of type `[0, n) -> INDEXTYPE`. In a counts representation, the counts must be an array of this type. This cannot be expressed in an offsets representation because offsets elements do not have a one-to-one relationship with logical jagged array elements. This could be taken as another argument for starts and stops over offsets.

Some applications of awkward-array may require data that is being filled while it is being accessed. This is possible if whole-array validity constraints on array shapes are not too strict. Assuming that basic arrays can be appended atomically, or at least their lengths can be increased atomically to reveal content filled before increasing their lengths, jagged arrays can atomically grow by

   . appending content first,
   . then appending stops,
   . then appending starts.

The length of the content is allowed to be greater than or equal to the maximum stop value, and the length of stops is allowed to be greater than or equal to the length of starts. The logical length of the jagged array is taken to be the length of starts. As described above, starts and stops must have the same shape, but only for dimensions other than the first dimension.

=== JaggedArray


=== ByteJaggedArray


== Product types


=== Table


== Sum types


=== UnionArray


== Option types


=== MaskedArray


=== BitMaskedArray


=== IndexedMaskedArray


== Indirection

_(pointers go here)_


=== IndexedArray


=== ByteIndexedArray


=== SparseArray


== Opaque objects


=== Mix-in Methods


=== ObjectArray


=== StringArray


== Non-contiguousness


=== ChunkedArray


=== AppendableArray


== Laziness


=== VirtualArray


== Methods defined on all arrays


== Serialization
